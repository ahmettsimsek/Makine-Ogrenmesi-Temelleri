{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-En Yakın Komşu(KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### en yakın komşunun, K değerine göre belirlendiği bir sınıflandırma yöntemidir. Denetimli öğrenmede sınıflandırma ve regresyon için kullanılan algoritmalardan biridir. En basit makine öğrenmesi algoritması olarak kabul edilir.\n",
    "##### KNN amacı, yeni bir örnek geldiğinde var olan öğrenme verisi üzerinde sınıflandırma yaparak onun en yakın K komşusuna bakarak örneğin sınıfına karar verir.\n",
    "##### K-NN algoritması sınıflandırma algoritmasıdır. Sınıflandırmak, belirli bir veri kümesini farklı sınıflara ayırma işlemidir. Sınıflandırma hem yapılandırılmış hem de yapılandırılmamış veri türleri üzerinde uygulanabilir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN algoritması sınıflandırılmak istenen bir veriyi daha önceki verilerle olan yakınlık ilişkisine göre sınıflandıran bir algoritmadır. Algoritma adının içinde bulunduğu “K” algoritmaya dahil edilecek veri kümesindeki veri sayısını ifade etmektedir. Yani algoritmada “k” adet komşu aranır. Bir tahmin yapmak istediğimizde, tüm veri setinde en yakın komşuları arar. Algoritmanın çalışmasında bir K değeri belirlenir. Bu K değerinin anlamı bakılacak eleman sayısıdır. Bir değer geldiğinde en yakın K kadar eleman alınarak gelen değer arasındaki uzaklık hesaplanır. İlgili uzaklılardan en yakın k komşu ele alınır. Öznitelik değerlerine göre k komşu veya komşuların sınıfına atanır. Seçilen sınıf, tahmin edilmesi beklenen gözlem değerinin sınıfı olarak kabul edilir. Yani yeni veri etiketlenmiş (label) olur. K-NN non-parametric ( parametrik olmayan ), lazy ( tembel ) bir öğrenme algoritmasıdır. lazy kavramını anlamaya çalışırsak “eager learning” aksine “lazy learning”’in bir eğitim aşaması yoktur. Eğitim verilerini öğrenmez, bunun yerine eğitim veri kümesini “ezberler”. Uzaklık hesaplama işleminde genelde Öklid fonksiyonu kullanılır. Öklid fonksiyonuna alternatif olarak Manhattan, Minkowski ve Hamming fonksiyonlarıda kullanılabilir. Uzaklık hesaplandıktan sonra sıralanır ve gelen değer uygun olan sınıfa atanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 041222](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/4caa72ba-3363-436a-9d50-bc818618ae7c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bir tahmin yapmak için KNN algoritması, lojistik veya doğrusal regresyonda olduğu gibi bir eğitim veri kümesinden öngörücü bir model hesaplamaz. Aslında, KNN'nin tahmine dayalı bir model oluşturmasına gerek yoktur. Bu nedenle, KNN için gerçek bir öğrenme aşaması yoktur. Bu yüzden genellikle tembel bir öğrenme yöntemi olarak kategorize edilir. Bir tahmin yapabilmek için, KNN herhangi bir eğitim aşaması olmadan bir sonuç üretmek için veri setini kullanır. KNN, bir tahmin yapmak için tüm veri kümesini depolar. KNN herhangi bir tahmine dayalı modeli hesaplamaz ve tembel öğrenme algoritmaları ailesinin bir parçasıdır. KNN, bir girdi gözlemi ile veri kümesindeki farklı gözlemler arasındaki benzerliği hesaplayarak tam zamanında (anında) tahminler yapar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 041356](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/23548c1e-e561-4d8b-a4b1-257237bb1b9d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yukarıdaki şekilde, kırmızı veya yeşil olarak sınıflandırılan veri noktalarında siyah bir veri noktası kırmızı ya da yeşil olabilecek iki sınıfı göstermektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN algoritmaları, sınıflandırılacak veri noktasına en yakın komşu olan bir k sayısına karar verir. K değeri 5 ise, o veri noktasına en yakın 5 Komşuyu arayacaktır. Bu örnekte, k = 4. KNN en yakın 4 komşuyu bulur. Bu veri noktasının bu komşulara yakın olması nedeniyle sadece bu sınıfa ait olacağı görülmektedir. K-en yakın komşu sınıflandırıcı algoritmalarının basit versiyonu, en yakın komşu sınıfı bularak hedef etiketini tahmin etmektir. Sınıflandırılacak noktaya en yakın sınıf, Öklid mesafesi kullanılarak hesaplanır. Mesafe, benzerliği ölçmek için kullanılır. İki örnek arasındaki mesafeyi ölçmenin birçok yolu vardır.\n",
    "\n",
    "• Manhattan Distance, |X1-X2| + |Y1-Y2|\n",
    "\n",
    "• Euclidean Distance, √((𝑥1−𝑥2)2)+√(𝑦1−𝑦2)2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 041655](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/8ecad059-db67-4640-b662-d776abde5c90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mesafe ölçüsünün de yalnızca sürekli değişkenler için geçerli olduğu unutulmamalıdır. Kategorik değişkenler durumunda Hamming mesafesi kullanılmalıdır. Veri setinde sayısal ve kategorik değişkenlerin bir karışımı olduğunda, 0 ile 1 arasındaki sayısal değişkenlerin standardizasyonu konusunu da gündeme getirir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 041807](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/02cbeb6a-e8ca-4136-84e2-0602b2fdc2a6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K'nin önemi nedir?\n",
    "\n",
    "##### K değeri büyüdükçe tahmine duyulan güveni artırır. Öte yandan K çok büyük bir değere sahipse, kararlar çarpık olabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K nasıl seçilir?\n",
    " K'ye karar vermek, K-en yakın Komşular'ın en kritik kısmıdır.\n",
    "\n",
    " K değeri küçükse, gürültü sonuca daha fazla bağımlı olacaktır. Bu gibi durumlarda\n",
    "modelin aşırı uyumu çok fazladır.\n",
    "\n",
    " K'nin değeri ne kadar büyükse, KNN'nin arkasındaki prensibi yok edecektir.\n",
    "\n",
    " Çapraz doğrulamayı kullanarak K'nin optimum değeri bulunabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 042052](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/f0534305-a815-4ada-b519-9563638d1316)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN algoritması sözde kod uygulaması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• İstenilen verileri yüklenir.\n",
    "\n",
    "• k parametresi belirlenir. Bu parametre verilen bir noktaya en yakın komşuların\n",
    "sayısıdır. Örneğin: k=2 olsun. Bu durumda en yakın 2 komşuya göre sınıflandırma\n",
    "yapılacaktır.\n",
    "\n",
    "• Örnek veri setine katılacak olan yeni verinin, mevcut verilere göre uzaklığı tek tek\n",
    "hesaplanır. İlgili uzaklık fonksiyonları yardımıyla.\n",
    "\n",
    "• İlgili uzaklılardan en yakın k komşu ele alınır. Öznitelik değerlerine göre k komşu veya\n",
    "komşuların sınıfına atanır.\n",
    "\n",
    "• Seçilen sınıf, tahmin edilmesi beklenen gözlem değerinin sınıfı olarak kabul edilir.\n",
    "Yani yeni veri etiketlenmiş (label) olur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN, anlaşılması oldukça basit bir algoritmadır. Bunun başlıca nedeni, tahmin yapabilmek için bir modele ihtiyaç duymamasıdır. Bunun tersi, tahminini yapabilmek için tüm gözlemlerini hafızasında tutması gerektiğidir. Bu nedenle, girdi veri kümesinin boyutuna dikkat etmeniz gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 042424](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/a658353b-37bb-4b59-a8ef-12e2e73aa7e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Ekran görüntüsü 2024-05-18 042553](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/5707b3d8-ca0a-46af-b99e-ab3cd7f38419)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Ekran görüntüsü 2024-05-18 042648](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/7f2f1a8b-92c2-4fb3-bb49-941b1899aae4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Varsayımları:\n",
    "\n",
    "#### 1. Standardizasyon\n",
    "Antrenman verilerindeki bağımsız değişkenler farklı birimlerde ölçüldüğünde, mesafeyi\n",
    "hesaplamadan önce değişkenleri standardize etmek önemlidir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 042920](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/071fc7c2-36e2-4c99-8ac9-b7fa92e8fe5d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Aykırı Değer\n",
    "Düşük k-değeri aykırı değerlere duyarlıdır ve daha yüksek bir K-değeri, daha fazla seçmenin\n",
    "tahmine karar vereceğini düşündüğü için aykırı değerlere karşı daha dirençlidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN'nin Artıları ve Eksileri\n",
    "\n",
    "#### Artıları:\n",
    " Anlaması kolay\n",
    "\n",
    " Veriler hakkında varsayım yok\n",
    "\n",
    " Hem sınıflandırma hem de regresyona uygulanabilir\n",
    "\n",
    " Çok sınıflı problemlerde kolayca çalışır\n",
    "\n",
    "#### Eksileri:\n",
    " Yoğun Bellek / Hesaplama açısından pahalı\n",
    "\n",
    " Veri ölçeğine duyarlı\n",
    "\n",
    " Nadir olay (çarpık) hedef değişkeni üzerinde iyi çalışmıyor\n",
    "\n",
    " Çok sayıda bağımsız değişken olduğunda mücadele\n",
    "\n",
    " Herhangi bir problem için, küçük bir k değeri, tahminlerde büyük bir varyansa yol\n",
    "\n",
    "açacaktır. Alternatif olarak, k değerini büyük bir değere ayarlamak, büyük bir model\n",
    "\n",
    "yanlılığına yol açabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En iyi K değeri nasıl bulunur?\n",
    "\n",
    "##### Çapraz doğrulama, optimal K değerini bulmanın akıllı bir yoludur. Model oluşturma sürecinden eğitim setinin bir alt kümesini dışarıda tutarak doğrulama hata oranını tahmin eder.\n",
    "\n",
    "##### Çapraz doğrulama (diyelim ki 10 kat doğrulama), eğitim setinin rastgele olarak yaklaşık eşit büyüklükte 10 gruba veya katlara bölünmesini içerir. Verilerin %90'ı modeli eğitmek için, kalan %10'u ise onu doğrulamak için kullanılır. Yanlış sınıflandırma oranı daha sonra %10 doğrulama verisi üzerinden hesaplanır. Bu prosedür 10 kez tekrarlanır. Farklı gözlem grupları, 10 defadan her biri bir doğrulama seti olarak ele alınır. Daha sonra ortalaması alınan doğrulama hatasının 10 tahminiyle sonuçlanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neden bir K-NN Algoritmasına ihtiyacımız var?\n",
    "\n",
    "##### Diyelim ki iki kategori var, yani Kategori A ve Kategori B ve elimizde yeni bir veri var. x1 noktası, dolayısıyla bu veri noktası bu kategorilerin hangisinde yer alacaktır. Bu tür sorunları çözmek için sorun için bir K-NN algoritmasına ihtiyacımız var. K-NN'nin yardımıyla kolayca tanımlayabiliriz. Belirli bir veri kümesinin kategorisi veya sınıfı. Aşağıdaki diyagramı göz önünde bulundurun:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Ekran görüntüsü 2024-05-18 043430](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/69745a12-63df-491a-935d-cd49c2d07a91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN nasıl çalışır?\n",
    "\n",
    "##### K-NN'nin çalışması aşağıdaki algoritmaya dayanarak açıklanabilir:\n",
    "o Adım-1: Komşuların K sayısını seçin\n",
    "\n",
    "o Adım-2: K sayıda komşunun Öklid uzaklığını hesaplayın\n",
    "\n",
    "o Adım-3: Hesaplanan Öklid mesafesine göre en yakın K komşuyu alın.\n",
    "\n",
    "o Adım-4: Bu k komşu arasında, her birindeki veri noktalarının sayısını sayın.\n",
    "\n",
    "o Adım-5: Yeni veri noktalarını, sayının belirlendiği kategoriye atayın.\n",
    "komşu maksimumdur.\n",
    "\n",
    "o Adım-6: Modelimiz hazır.\n",
    "\n",
    "##### ile KNN modelimizi oluşturabiliriz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 043749](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/b19086a9-8217-4ba9-86e5-0a2fc3db0cfc)\n",
    "![Ekran görüntüsü 2024-05-18 043804](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/c38b2fe2-732b-4afd-8475-55ac2077177e)\n",
    "![Ekran görüntüsü 2024-05-18 043815](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/38f5f7fc-e467-4e9c-ae68-4897252c43e3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-en yakın komşu algoritması örneği Pyhon Kodu ile;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris \n",
    "  \n",
    "# Loading data \n",
    "irisData = load_iris() \n",
    "  \n",
    "# Create feature and target arrays \n",
    "X = irisData.data \n",
    "y = irisData.target \n",
    "  \n",
    "# Split into training and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "             X, y, test_size = 0.2, random_state=42) \n",
    "  \n",
    "knn = KNeighborsClassifier(n_neighbors=7) \n",
    "  \n",
    "knn.fit(X_train, y_train) \n",
    "  \n",
    "# Predict on dataset which model has not seen before \n",
    "print(knn.predict(X_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yukarıda gösterilen örnekte aşağıdaki adımlar gerçekleştirilir:\n",
    "\n",
    "K-en yakın komşu algoritması scikit-learn paketinden içe aktarılır.\n",
    "\n",
    "Özellik ve hedef değişkenler oluşturun.\n",
    "\n",
    "Verileri eğitim ve test verilerine bölün.\n",
    "\n",
    "Komşular değerini kullanarak bir KN modeli oluşturun.\n",
    "\n",
    "Verileri modele göre eğitin veya sığdırın.\n",
    "\n",
    "Geleceği tahmin et.\n",
    "\n",
    "##### Denetimli makine öğrenimi problemini çözmek için KN algoritmasını nasıl kullanabileceğimizi gördük. Ancak modelin doğruluğunu nasıl ölçebilirim?\n",
    "\n",
    "##### Yukarıdaki modelin performansını tahmin ettiğimiz aşağıda gösterilen bir örneği düşünün:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "# Loading data \n",
    "irisData = load_iris() \n",
    "\n",
    "# Create feature and target arrays \n",
    "X = irisData.data \n",
    "y = irisData.target \n",
    "\n",
    "# Split into training and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "\t\t\tX, y, test_size = 0.2, random_state=42) \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7) \n",
    "\n",
    "knn.fit(X_train, y_train) \n",
    "\n",
    "# Calculate the accuracy of the model \n",
    "print(knn.score(X_test, y_test)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Doğruluğu:\n",
    "Şimdiye kadar çok iyi. Ancak veri kümesi için doğru k değerine nasıl karar verilir? Açıkçası, beklenen k değeri aralığını elde etmek için verilere aşina olmamız gerekir, ancak tam k değerini elde etmek için modeli beklenen her k değeri için test etmemiz gerekir. Aşağıda gösterilen örneğe bakın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "irisData = load_iris() \n",
    "\n",
    "# Create feature and target arrays \n",
    "X = irisData.data \n",
    "y = irisData.target \n",
    "\n",
    "# Split into training and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "\t\t\tX, y, test_size = 0.2, random_state=42) \n",
    "\n",
    "neighbors = np.arange(1, 9) \n",
    "train_accuracy = np.empty(len(neighbors)) \n",
    "test_accuracy = np.empty(len(neighbors)) \n",
    "\n",
    "# Loop over K values \n",
    "for i, k in enumerate(neighbors): \n",
    "\tknn = KNeighborsClassifier(n_neighbors=k) \n",
    "\tknn.fit(X_train, y_train) \n",
    "\t\n",
    "\t# Compute training and test data accuracy \n",
    "\ttrain_accuracy[i] = knn.score(X_train, y_train) \n",
    "\ttest_accuracy[i] = knn.score(X_test, y_test) \n",
    "\n",
    "# Generate plot \n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy') \n",
    "plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy') \n",
    "\n",
    "plt.legend() \n",
    "plt.xlabel('n_neighbors') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Çıktı"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-18 044439](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/6a2f75c7-bce0-4385-ba39-929984164aec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Burada yukarıda gösterilen örnekte, yüksek doğruluğa sahip olduğumuz k değerini görmek için bir çizim oluşturuyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Algoritması - En Yakın Komşuları Bulma konusunda daha fazla detaya ulaşmak için, benim de örnek için Yararlandığım  sayfaya aşağıdaki linkten ulaşabilirsiniz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/k-nearest-neighbor-algorithm-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
