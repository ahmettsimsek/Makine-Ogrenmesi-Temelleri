{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauss Karışım Modelleri (GMM) kullanarak Beklenti-Maksimizasyon (EM) Kümeleme:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Ortalamalarının en büyük dezavantajlarından biri, küme merkezi için ortalama değerin naif kullanımıdır. Aşağıdaki resme bakarak bunun bir şeyleri yapmanın en iyi yolu olmadığını anlayabiliriz. Sol tarafta, aynı ortalamaya merkezlenmiş farklı yarıçaplara sahip iki dairesel küme olduğu insan gözüne oldukça açık görünüyor. K-Ortalamalar bunun üstesinden gelemez çünkü kümelerin ortalama değerleri birbirine çok yakındır. K-Ortalamalar, yine ortalamanın küme merkezi olarak kullanılması sonucunda kümelerin dairesel olmadığı durumlarda başarısız olur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-17 072305](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/7c808f65-f3bd-4ee9-a653-ddac58526da7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Gauss Karışım Modelleri (GMM'ler) bize K-Ortalamalarından daha fazla esneklik sağlar. GMM'ler ile veri noktalarının Gauss olarak dağıtıldığını varsayıyoruz; bu, ortalamayı kullanarak döngüsel olduklarını söylemekten daha az kısıtlayıcı bir varsayımdır. Bu şekilde, kümelerin şeklini açıklamak için iki parametremiz var: ortalama ve standart sapma! İki boyutlu bir örnek alırsak, bu, kümelerin her türlü eliptik şekli alabileceği anlamına gelir (çünkü hem x hem de y yönlerinde standart bir sapmaya sahibiz). Böylece, her Gauss dağılımı tek bir kümeye atanır.\n",
    "\n",
    "##### Her küme için Gauss'un parametrelerini bulmak için (örneğin ortalama ve standart sapma), Beklenti-Maksimizasyon (EM) adı verilen bir optimizasyon algoritması kullanacağız. Kümelere uydurulan Gaussian'ların bir örneği olarak aşağıdaki grafiğe bir göz atın. Daha sonra GMM'leri kullanarak Beklenti-Maksimizasyon kümeleme sürecine geçebiliriz. Yani özetlememiz gerekirse, K-Means olmuyorsa Gauss ile yapıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-17 072453](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/bdcc0920-a6b9-4321-863d-edc33560016f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grafikte gördüğümüz gibi dairesel çizersek dışarıda kalırdı ancak Gauss ile daha elisik aldık ama bu durumda bile dışarda kalanlar olduğu için başarımızı düşürmektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Küme sayısını seçerek (K-Means'ın yaptığı gibi) ve her küme için Gauss dağılım\n",
    "parametrelerini rastgele başlatarak başlıyoruz. Verilere de hızlıca göz atarak ilk\n",
    "parametreler için iyi bir tahmin sağlamaya çalışılabilir. Yine de, yukarıdaki grafikte de\n",
    "görülebileceği gibi, bu% 100 gerekli değildir çünkü Gauss bize çok zayıf olarak\n",
    "başlarlar, ancak hızla optimize edilirler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Her küme için bu Gauss dağılımları göz önüne alındığında, her veri noktasının belirli\n",
    "bir kümeye ait olma olasılığı hesaplanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Bu olasılıklara dayanarak, kümeler içindeki veri noktalarının olasılıklarını maksimize\n",
    "edecek şekilde Gauss dağılımları için yeni bir dizi parametre hesaplıyoruz.  Ayrıca noktaların çoğunun “üstten-sağdan-aşağıya” olduğunu da görebiliriz. Bu nedenle standart sapma, olasılıkların ağırlıklandırdığı toplamı maksimize etmek için bu noktalara daha uygun bir elips oluşturmak üzere değişir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Dağıtımların yinelemeden yinelemeye pek değişmediği yakınsamaya kadar 2. ve 3. adımlar yinelemeli olarak tekrarlanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GMM kullanmanın 2 önemli avantajı vardır. Birincisi,\n",
    "GMM'ler küme kovaryansı açısından KOrtalamalarına göre çok daha esnektir; standart sapma parametresi nedeniyle, kümeler dairelerle sınırlı olmak yerine herhangi bir elips şeklini alabilir. Dolayısıyla, bir veri noktası üst üste binen iki kümenin ortasındaysa, sınıf 1'e yüzde X ve yüzde Y yüzde 2'ye ait olduğunu söyleyerek sınıfını tanımlayabiliriz. Yani GMM'ler karma üyeliği destekler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Örnek olarak alttaki veriye bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('biometric_data_simple.txt',delimiter=',')\n",
    "\n",
    "women = data[data[:,0] == 1]\n",
    "men = data[data[:,0] == 2]\n",
    "\n",
    "plt.xlim(55,80)\n",
    "plt.ylim(80,280)\n",
    "plt.plot (women[:,1],women[:,2], 'b.')\n",
    "plt.hold(True)\n",
    "plt.plot (men[:,1],men[:,2], 'r.')\n",
    "plt.xlabel('boy (inch)')\n",
    "plt.ylabel('agirlik (pound)')\n",
    "plt.savefig('mixnorm_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-17 072920](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/0376843b-e461-4d89-b8db-37c296dfde71)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu grafik kadınlar ve erkeklerin boy (height) ve kilolarını (weight) içeren bir veri setinden geliyor, veri setinde erkekler ve kadınlara ait olan ölçümler önceden işaretlenmiş / etiketlenmiş (labeled), biz de bu işaretleri kullanarak kadınları kırmızı erkekleri mavi ile grafikledik. Ama bu işaretler / etiketler verilmiş olsun ya da olmasın, kavramsal olarak düşünürsek eğer bu veriye bir dağılım uydurmak (fit) istersek bir karışım kullanılması gerekli, çünkü iki tepe noktasiyle daha rahat temsil edileceğini düşündüğümüz bir durum var ortada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate gaussian, contours\n",
    "#\n",
    "import scipy.stats\n",
    "import em\n",
    "\n",
    "data = np.loadtxt('biometric_data_simple.txt',delimiter=',')\n",
    "\n",
    "women = data[data[:,0] == 1]\n",
    "men = data[data[:,0] == 2]\n",
    "\n",
    "plt.xlim(55,80)\n",
    "plt.ylim(80,280)\n",
    "plt.plot (women[:,1],women[:,2], 'b.')\n",
    "plt.hold(True)\n",
    "plt.plot (men[:,1],men[:,2], 'r.')\n",
    "plt.xlabel('boy (inch)')\n",
    "plt.ylabel('agirlik (pound)')\n",
    "plt.hold(True)\n",
    "\n",
    "x = np.arange(55., 80., 1)\n",
    "y = np.arange(80., 280., 1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = np.zeros(X.shape)\n",
    "nx, ny = X.shape\n",
    "mu1 = np.array([  72.89350086,  193.21741426])\n",
    "sigma1 = np.matrix([[    7.84711283,    25.03111826],\n",
    "                    [   25.03111826,  1339.70289046]])\n",
    "for i in xrange(nx):\n",
    "    for j in xrange(ny):\n",
    "        Z[i,j] = em.norm_pdf(np.array([X[i,j], Y[i,j]]),mu1,sigma1)\n",
    "\n",
    "levels = np.linspace(Z.min(), Z.max(), 4)\n",
    "\n",
    "plt.contour(X, Y, Z, colors='b', levels=levels)\n",
    "plt.hold(True)\n",
    "\n",
    "Z = np.zeros(X.shape)\n",
    "nx, ny = X.shape\n",
    "mu2 = np.array([  66.15903841,  135.308125  ])\n",
    "sigma2 = np.matrix([[  14.28189396,   51.48931033],\n",
    "                    [  51.48931033,  403.09566456]])\n",
    "for i in xrange(nx):\n",
    "    for j in xrange(ny):\n",
    "        Z[i,j] = em.norm_pdf(np.array([X[i,j], Y[i,j]]),mu2,sigma2)\n",
    "\n",
    "levels = np.linspace(Z.min(), Z.max(), 4)\n",
    "\n",
    "plt.contour(X, Y, Z, colors='r', levels=levels)\n",
    "plt.savefig('mixnorm_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ekran görüntüsü 2024-05-17 073018](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/b6dc09a9-0872-47ce-97fa-077e61dd84c4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu karışım içindeki Gaussian'ları üstteki gibi çizebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gauss Karışım Modelleri (GMM) kullanarak Beklenti-Maksimizasyon (EM) Kümeleme konusunda daha fazla detaya ulaşmak için, benim de örnek için Yararlandığım  sayfaya aşağıdaki linkten ulaşabilirsiniz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://burakbayramli.github.io/dersblog/stat/stat_110_gmm/gaussian_karisim_modeli__gmm__ile_kumelemek.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
