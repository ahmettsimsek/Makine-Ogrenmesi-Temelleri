{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Anomali tespiti Algoritması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veri analizinde, anomali tespiti (aynı zamanda aykırı değer tespiti), verilerin çoğunluğundan önemli ölçüde farklılaşarak şüphe uyandıran nadir öğelerin, olayların veya gözlemlerin tanımlanmasıdır. Tipik olarak anormal öğeler, banka dolandırıcılığı, yapısal bir kusur, tıbbi sorunlar veya bir metindeki hatalar gibi bir tür soruna dönüşecektir. Anormallikler ayrıca aykırı değerler, yenilikler, gürültü, sapmalar ve istisnalar olarak da adlandırılmaktadır.\n",
    "\n",
    "##### Özellikle, kötüye kullanım ve ağa izinsiz giriş tespiti bağlamında, ilginç nesneler genellikle nadir nesneler değil, beklenmedik etkinlik patlamalarıdır. Bu model, bir aykırı değerin nadir bir nesne olarak genel istatistiksel tanımına uymaz ve uygun şekilde bir araya getirilmediği sürece birçok aykırı değer algılama yöntemi (özellikle denetimsiz yöntemler) bu tür verilerde başarısız olmaktadır. Bunun yerine, bir küme analizi algoritması, bu modellerin oluşturduğu mikro kümeleri tespit edebilmektedir.\n",
    "\n",
    "##### Üç geniş anomali tespit tekniği kategorisi mevcuttur[4]. Denetimsiz anomali tespit teknikleri, veri setindeki örneklerin çoğunluğunun normal olduğu varsayımı altında, veri setinin geri kalanına en az uyan örnekleri arayarak etiketlenmemiş bir test veri setindeki anormallikleri tespit etmektedir. Denetimli anomali tespit teknikleri, \"normal\" ve \"anormal\" olarak etiketlenmiş bir veri seti gerektirir ve bir sınıflandırıcının eğitimini içermektedir (diğer birçok istatistiksel sınıflandırma probleminden temel fark, aykırı değer tespitinin doğal dengesiz doğasıdır). Yarı denetimli anomali tespit teknikleri, belirli bir normal eğitim veri setinden normal davranışı temsil eden bir model oluşturur ve ardından kullanılan model tarafından bir test örneğinin oluşturulma olasılığını test etmektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/ahmettsimsek/Makine-Ogrenmesi-Temelleri/assets/124433579/706f399c-4fa9-4bf9-85bc-2de1554a9948)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomali tespiti için çalışan bir Python Kodu örneği "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,\"../../../\")\n",
    "import h2o\n",
    "\n",
    "def anomaly(ip, port):\n",
    "    h2o.init(ip, port)\n",
    "\n",
    "    print \"Deep Learning Anomaly Detection MNIST\"\n",
    "\n",
    "    train = h2o.import_frame(h2o.locate(\"bigdata/laptop/mnist/train.csv.gz\"))\n",
    "    test = h2o.import_frame(h2o.locate(\"bigdata/laptop/mnist/test.csv.gz\"))\n",
    "\n",
    "    predictors = range(0,784)\n",
    "    resp = 784\n",
    "\n",
    "    # unsupervised -> drop the response column (digit: 0-9)\n",
    "    train = train[predictors]\n",
    "    test = test[predictors]\n",
    "\n",
    "    # 1) LEARN WHAT'S NORMAL\n",
    "    # train unsupervised Deep Learning autoencoder model on train_hex\n",
    "    ae_model = h2o.deeplearning(x=train[predictors], training_frame=train, activation=\"Tanh\", autoencoder=True,\n",
    "                                hidden=[50], l1=1e-5, ignore_const_cols=False, epochs=1)\n",
    "\n",
    "    # 2) DETECT OUTLIERS\n",
    "    # anomaly app computes the per-row reconstruction error for the test data set\n",
    "    # (passing it through the autoencoder model and computing mean square error (MSE) for each row)\n",
    "    test_rec_error = ae_model.anomaly(test)\n",
    "\n",
    "    # 3) VISUALIZE OUTLIERS\n",
    "    # Let's look at the test set points with low/median/high reconstruction errors.\n",
    "    # We will now visualize the original test set points and their reconstructions obtained\n",
    "    # by propagating them through the narrow neural net.\n",
    "\n",
    "    # Convert the test data into its autoencoded representation (pass through narrow neural net)\n",
    "    test_recon = ae_model.predict(test)\n",
    "\n",
    "    # In python, the visualization could be done with tools like numpy/matplotlib or numpy/PIL\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    h2o.run_test(sys.argv, anomaly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
